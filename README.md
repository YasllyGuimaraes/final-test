<div id="top"></div>

  <h1 align="center">Toxicity Text Detection - Dell Lead</h1>

  </p>
</div>

## üìù Descri√ß√£o do Projeto

Projeto de avalia√ß√£o final da mentoria Dell Lead.

### Avalia√ß√£o

O objetivo deste projeto √© criar um modelo em que classifica um coment√°rio em t√≥xicos ou n√£o-t√≥xicos. Ser√£o avaliados diferentes aspectos neste projeto: tanto a capacidade de apresentar e interpretar informa√ß√µes, como o pr√©-processamento, treinamento e avalia√ß√£o dos resultados.

### Conjunto de dados

O conjunto de dados a ser utilizado nesta avalia√ß√£o √© uma sub-amostra de um conjunto de dados p√∫blico dispon√≠vel no Kaggle. Ele √© composto por coment√°rios da Wikipedia que foram rotulados em diferentes tipos de toxidade. O conjunto de dados foi adaptado para ter somente coment√°rios t√≥xicos e n√£o-t√≥xicos.

## ‚òï Procedimentos

### An√°lise explorat√≥ria dos dados

Realize uma An√°lise Explorat√≥ria dos Dados (EDA) no conjunto de dados.

### Etapa de experimentos com diferentes modelos

Realize diversos experimentos considerando diferentes m√©todos de classifica√ß√£o para determinar o modelo mais adequado para o problema em quest√£o. 

Quest√µes que ser√£o consideradas para compor a pontua√ß√£o total:
* Pr√©-processamento dos dados
* Escolha e implementa√ß√£o do modelo
* Otimiza√ß√£o de hiper-par√¢metros
* Acur√°cia
* Escolha de m√©tricas

### Script de classifica√ß√£o

Deve-se implementar um script para classificar novos textos (os novos textos estar√£o na mesma estrutura dos dados de treinamento, em um arquivo csv). O script deve carregar o m√©todo de normaliza√ß√£o (se usado) e o modelo salvo ap√≥s o treinamento. √â necess√°rio salvar um arquivo .csv com os textos e o resultado da classifica√ß√£o.

## üõ† Tecnologias utilizadas

As principais ferramentas para construir esse projeto foram:

* [python](https://www.python.org/)
* [pandas](https://pandas.pydata.org/)
* [matplotlib](https://matplotlib.org/)
* [seaborn](https://seaborn.pydata.org/)
* [nltk](https://www.nltk.org/)
* [wordcloud](https://pypi.org/project/wordcloud/)
* [pickle](https://docs.python.org/3/library/pickle.html)
* [sklearn](https://scikit-learn.org/stable/)

## üìù Autora

- Yaslly Guimar√£es - [YasllyGuimaraes](https://github.com/YasllyGuimaraes)
      
## ‚òéÔ∏è Contato

Linkedin - [yasllyguimaraes](https://www.linkedin.com/in/yasllyguimaraes/)

Project Link: [toxicity-text-detection](https://github.com/YasllyGuimaraes/toxicity-text-detection)

<p align="right">(<a href="#top">back to top</a>)</p>
